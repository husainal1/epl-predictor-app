# -*- coding: utf-8 -*-
"""Predicting EPL Player Performance

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kr0yQPJYDb-rBHKq6XedQceqKWEcRM05
"""

# basic setup - install libraries
!pip install pandas==2.2.2 numpy==1.26.4 requests==2.32.3 tqdm==4.66.5 scikit-learn==1.5.2 xgboost==2.1.1

#imports - pandas/numpy for data, requests for api, xgboost + sklearn for model
import pandas as pd, numpy as np, requests, time, json, math, datetime as dt
from tqdm import tqdm
from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor

pd.set_option("display.max_columns", 200)

# function to grab json data from the FPL api with a retry
BASE = "https://fantasy.premierleague.com/api"

def get_json(url, retries=5, sleep=0.5):
    for i in range(retries):
        r = requests.get(url, timeout=30)
        if r.status_code == 200:
            return r.json()
        time.sleep(sleep*(i+1))
    r.raise_for_status()

# grab static data: players, teams, fixtures
bootstrap = get_json(f"{BASE}/bootstrap-static/")
players_meta = pd.DataFrame(bootstrap['elements'])
teams_meta   = pd.DataFrame(bootstrap['teams'])
fixtures     = pd.DataFrame(get_json(f"{BASE}/fixtures/"))

# keep only useful team cols
teams = teams_meta[['id','name','short_name','strength',
                    'strength_attack_home','strength_attack_away',
                    'strength_defence_home','strength_defence_away']].rename(columns={'id':'team_id'})

# minimal player info
players = players_meta[['id','first_name','second_name','web_name','team','element_type']] \
            .rename(columns={'id':'player_id','team':'team_id'}) \
            .merge(teams, on='team_id', how='left')

players.head()

# function to get match-by-match history for a player
def fetch_player_history(pid):
    j = get_json(f"{BASE}/element-summary/{pid}/")
    df = pd.DataFrame(j.get('history', []))
    if df.empty:
        return df
    needed = ['element','opponent_team','round','minutes','total_points','goals_scored','assists',
              'ict_index','creativity','influence','threat',
              'expected_goals','expected_assists','expected_goal_involvements',
              'expected_goals_conceded','was_home','kickoff_time']
    for c in needed:
        if c not in df.columns: df[c] = np.nan
    df['player_id'] = pid
    return df

# loop over all players and get their match history
all_hist = []
for pid in tqdm(players['player_id'], desc="fetching players"):
    try:
        h = fetch_player_history(pid)
        if not h.empty: all_hist.append(h)
    except:
        pass  # if one player fails, skip

hist = pd.concat(all_hist, ignore_index=True)
hist['kickoff_time'] = pd.to_datetime(hist['kickoff_time'], errors='coerce')
hist['round'] = pd.to_numeric(hist['round'], errors='coerce')
hist['was_home'] = hist['was_home'].astype('Int64')
hist = hist[hist['kickoff_time'].notna()].sort_values(['player_id','kickoff_time']).reset_index(drop=True)

hist.head()

# add opponent info (strength etc.)
opp = teams.rename(columns={'team_id':'opp_team_id','name':'opp_name','short_name':'opp_short_name',
                            'strength':'opp_strength',
                            'strength_defence_home':'opp_strength_defence_home',
                            'strength_defence_away':'opp_strength_defence_away'})

hist = hist.merge(players[['player_id','team_id','web_name','element_type',
                           'strength','strength_attack_home','strength_attack_away',
                           'strength_defence_home','strength_defence_away']],
                  on='player_id', how='left')

hist = hist.merge(opp[['opp_team_id','opp_strength','opp_strength_defence_home','opp_strength_defence_away']],
                  left_on='opponent_team', right_on='opp_team_id', how='left')

hist['team_strength_diff'] = hist['strength'] - hist['opp_strength']
hist[['web_name','round','total_points','minutes','team_strength_diff']].head(10)

# add lag + rolling features so model can see "recent form"
def add_player_features(df, lags=(1,2,3), windows=(3,5,8)):
    df = df.copy()
    grp = df.groupby('player_id', group_keys=False)
    base_cols = ['total_points','minutes','goals_scored','assists',
                 'ict_index','creativity','influence','threat',
                 'expected_goals','expected_assists','expected_goal_involvements']

    # lag features
    for col in base_cols:
        for L in lags:
            df[f'{col}_lag{L}'] = grp[col].shift(L)

    # rolling means/sums
    for W in windows:
        for col in base_cols:
            df[f'{col}_roll{W}_mean'] = grp[col].shift(1).rolling(W).mean()
            df[f'{col}_roll{W}_sum']  = grp[col].shift(1).rolling(W).sum()

    # availability
    df['played_last_match'] = grp['minutes'].shift(1).fillna(0).gt(0).astype(int)
    df['played_last3_pct']  = grp['minutes'].shift(1).rolling(3).apply(lambda x: np.mean(x>0), raw=True)

    # attack vs defence diff
    df['attack_v_def_diff'] = np.where(
        df['was_home']==1,
        df['strength_attack_home'] - df['opp_strength_defence_away'],
        df['strength_attack_away'] - df['opp_strength_defence_home']
    )

    # time features
    df['month'] = df['kickoff_time'].dt.month
    df['dow'] = df['kickoff_time'].dt.dayofweek
    return df

fe = add_player_features(hist)

# looking to predict NEXT match total_points
fe['y_next_points'] = fe.groupby('player_id')['total_points'].shift(-1)

# drop rows that donâ€™t have enough history/future
model_df = fe.dropna(subset=['y_next_points','total_points_lag1','minutes_lag1']).copy()
model_df.shape

exclude = {'y_next_points','total_points','kickoff_time','web_name','opp_name','opp_short_name',
           'opp_team_id','team_id','opponent_team','name','short_name'}
feature_cols = [c for c in model_df.columns if c not in exclude and c != 'was_home'
                and pd.api.types.is_numeric_dtype(model_df[c])]

X = model_df[feature_cols].fillna(0)
y = model_df['y_next_points'].astype(float)
groups = model_df['player_id']

# baseline = 3 game avg
baseline = model_df['total_points_roll3_mean'].fillna(model_df['total_points_lag1'])

# groupkfold so same player doesn't leak train/val
gkf = GroupKFold(n_splits=5)
oof_pred = np.zeros(len(model_df))

for tr, va in gkf.split(X, y, groups):
    model = XGBRegressor(
        n_estimators=600, learning_rate=0.05, max_depth=6,
        subsample=0.8, colsample_bytree=0.8,
        random_state=42, n_jobs=-1, tree_method="hist"
    )
    model.fit(X.iloc[tr], y.iloc[tr], eval_set=[(X.iloc[va], y.iloc[va])], verbose=False)
    oof_pred[va] = model.predict(X.iloc[va])

print("Model MAE:", mean_absolute_error(y, oof_pred))
print("Baseline MAE:", mean_absolute_error(y, baseline))

final_model = XGBRegressor(
    n_estimators=800, learning_rate=0.04, max_depth=6,
    subsample=0.9, colsample_bytree=0.9,
    random_state=42, n_jobs=-1, tree_method="hist"
)
final_model.fit(X, y, verbose=False)

# Build latest snapshot per player
fe = add_player_features(hist)

# next-match target for training
# fe['y_next_points'] = fe.groupby('player_id')['total_points'].shift(-1)

# latest row per player by time
latest = (
    fe.sort_values(['player_id','kickoff_time'])
      .groupby('player_id')
      .tail(1)
      .copy()
)

# Add print statement to inspect latest columns before first merge (with players)
print("Columns of latest before first merge (with players):")
print(latest.columns)
print("\nHead of latest before first merge (with players):")
display(latest.head())


# bring in minimal player meta (select only the needed columns to avoid suffixes)
players_min = players[['player_id','team_id','web_name','element_type',
                       'strength','strength_attack_home','strength_attack_away',
                       'strength_defence_home','strength_defence_away']].copy()

latest = latest.merge(players_min, on='player_id', how='left')

# Add print statement to inspect latest columns after first merge (with players):")
print("\nColumns of latest after first merge (with players):")
print(latest.columns)
print("\nHead of latest after first merge (with players):")
display(latest.head())


# sanity: ensure 'team_id' exists (handle accidental suffixes)
if 'team_id' not in latest.columns:
    for cand in ['team_id_x','team_id_y']:
        if cand in latest.columns:
            latest = latest.rename(columns={cand: 'team_id'})
            break

# Next gameweek fixtures
upcoming = fixtures.copy()
next_gw = upcoming.loc[(~upcoming['finished']) & (upcoming['event'].notna()), 'event'].min()

if pd.isna(next_gw):
    print("No upcoming gameweek found yet.")
else:
    upcoming_next = upcoming[(upcoming['event']==next_gw) & (~upcoming['finished'])].copy()

    # Add print statements to check upcoming_next
    print("\nUpcoming next gameweek fixtures (upcoming_next):")
    print("Shape:", upcoming_next.shape)
    print("Columns:", upcoming_next.columns)
    display(upcoming_next.head())


    # map each team to (opp_team_id, was_home)
    home = upcoming_next[['team_h','team_a']].rename(columns={'team_h':'team_id','team_a':'opp_team_id'})
    home['was_home'] = 1
    away = upcoming_next[['team_a','team_h']].rename(columns={'team_a':'team_id','team_h':'opp_team_id'})
    away['was_home'] = 0
    team_next = pd.concat([home, away], ignore_index=True)

    # Add print statements to check team_next
    print("\nTeam next fixture mapping (team_next):")
    print("Shape:", team_next.shape)
    print("Columns:", team_next.columns)
    display(team_next.head())


    # join fixture mapping to latest
    # This merge adds 'opp_team_id_y' and 'was_home_y' to latest
    latest = latest.merge(team_next, on='team_id', how='left')

    # Add print statement to check latest columns after merging with team_next
    print("\nColumns of latest after merge with team_next:")
    print(latest.columns)
    print("\nHead of latest after merge with team_next:")
    display(latest.head())

    # Check if opp_team_id_y is present and has non-null values before merging with opp_strengths
    if 'opp_team_id_y' not in latest.columns or latest['opp_team_id_y'].isnull().all():
        print("Warning: 'opp_team_id_y' column is missing or all null after merging with team_next. Cannot merge with opponent strengths.")
    else:
        # bring opponent strengths
        opp_strengths = teams.rename(columns={
            'team_id':'opp_team_id',
            'strength':'opp_strength',
            'strength_defence_home':'opp_strength_defence_home',
            'strength_defence_away':'opp_strength_defence_away'
        })[['opp_team_id','opp_strength','opp_strength_defence_home','opp_strength_defence_away']]

        # Now merge latest with opp_strengths on 'opp_team_id_y'
        latest = latest.merge(opp_strengths, left_on='opp_team_id_y', right_on='opp_team_id', how='left')

        # Add print statement to check latest columns after merging with opp_strengths
        print("\nColumns of latest after merge with opp_strengths:")
        print(latest.columns)
        print("\nHead of latest after merge with opp_strengths:")
        display(latest.head())


        # recompute venue-aware attack vs defence diff for the UPCOMING match
        # Use the correct suffixed column names for the calculation
        latest['attack_v_def_diff'] = np.where(
            latest['was_home_y'] == 1,
            latest['strength_attack_home_x'] - latest['opp_strength_defence_away_y'],
            latest['strength_attack_away_x'] - latest['opp_strength_defence_home_y']
        )

        # Predict
        # use same feature set you trained with
        # Ensure X_pred has the same columns as X used for training
        X_pred = latest.reindex(columns=feature_cols).fillna(0)
        latest['pred_next_points'] = final_model.predict(X_pred)

        # tidy columns for viewing
        TEAM_MAP = teams.set_index('team_id')['short_name'].to_dict()
        POS_MAP  = {1:'GK', 2:'DEF', 3:'MID', 4:'FWD'}
        # Use the correct suffixed column names for mapping
        latest['team'] = latest['team_id'].map(TEAM_MAP) # team_id did not get suffix after first merge, but will after second, need team_id_x
        latest['opp']  = latest['opp_team_id_y'].map(TEAM_MAP)
        latest['position'] = latest['element_type_x'].map(POS_MAP) # element_type got suffix _x


        latest['pred_next_points'] = latest['pred_next_points'].round(2)

        # final table (pandas)
        # Use the correct suffixed column names for the final table
        final_tbl = latest[['web_name_x','position','team','opp','was_home_y','pred_next_points']] \
                        .sort_values('pred_next_points', ascending=False) \
                        .reset_index(drop=True)

        # show top 50
        print(final_tbl.head(50))

# Define Big 6
BIG6 = ["ARS", "CHE", "LIV", "MCI", "MUN", "TOT"]

# Exclude Big 6 players
underdogs = final_tbl[~final_tbl['team'].isin(BIG6)].copy()

# Sort by predicted points
underdogs = underdogs.sort_values('pred_next_points', ascending=False)

# Top 5 bargains
top5_underdogs = underdogs.head(5)

print("Top 5 bargain underdogs (non-Big 6 teams):")
# Use the correct column name 'web_name_x'
print(top5_underdogs[['web_name_x','team','position','pred_next_points']])


print("\n----------------------------------------\n")

# Find best forwards for their price
# Ensure 'latest' DataFrame is accessible and contains 'value' (price), 'position', and 'web_name_x'
if 'value' in latest.columns and 'position' in latest.columns and 'web_name_x' in latest.columns:
    forwards = latest[latest['position'] == 'FWD'].copy()

    # Calculate points per price, handling potential division by zero
    forwards['points_per_price'] = np.where(forwards['value'] > 0, forwards['pred_next_points'] / (forwards['value'] / 10.0), 0) # Value is in 0.1M increments

    # Sort by points per price
    best_value_forwards = forwards.sort_values('points_per_price', ascending=False)

    print("Top forwards for their price:")
    # Display relevant columns using correct names
    print(best_value_forwards[['web_name_x','team','position','value','pred_next_points','points_per_price']].head(20))
else:
    print("Required columns ('value', 'position', or 'web_name_x') not found in the latest data.")